{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea-1704/Pytorch_Geometric_tutorial/blob/main/train_model_baseline_f1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zNziUzq9nTdU",
        "outputId": "a0b1d4fe-2096-4719-a2c6-94bfa37a8edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt24cpu)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt24cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt24cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt24cpu)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Requirement already satisfied: torch-geometric==2.6.0 in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.6.0) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.6.0) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.6.0) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.6.0) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.6.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.6.0) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.6.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.6.0) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.6.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.6.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.6.0) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.6.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.6.0) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.6.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.6.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.6.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.6.0) (2025.1.31)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
            "Collecting pyg-lib\n",
            "  Using cached https://data.pyg.org/whl/torch-2.4.0%2Bcpu/pyg_lib-0.4.0%2Bpt24cpu-cp311-cp311-linux_x86_64.whl (1.3 MB)\n",
            "Installing collected packages: pyg-lib\n",
            "Successfully installed pyg-lib-0.4.0+pt24cpu\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch_frame==1.2.2 (from versions: 0.1.0, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch_frame==1.2.2\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: relbench==1.0.0 in /usr/local/lib/python3.11/dist-packages (from relbench[full]==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from relbench==1.0.0->relbench[full]==1.0.0) (2.2.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from relbench==1.0.0->relbench[full]==1.0.0) (1.8.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from relbench==1.0.0->relbench[full]==1.0.0) (18.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from relbench==1.0.0->relbench[full]==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: duckdb in /usr/local/lib/python3.11/dist-packages (from relbench==1.0.0->relbench[full]==1.0.0) (1.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from relbench==1.0.0->relbench[full]==1.0.0) (1.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from relbench==1.0.0->relbench[full]==1.0.0) (4.13.1)\n",
            "Requirement already satisfied: pytorch_frame>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from relbench[full]==1.0.0) (0.2.5)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (from relbench[full]==1.0.0) (2.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch_frame>=0.2.3->relbench[full]==1.0.0) (2.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pytorch_frame>=0.2.3->relbench[full]==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from pytorch_frame>=0.2.3->relbench[full]==1.0.0) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->relbench==1.0.0->relbench[full]==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->relbench==1.0.0->relbench[full]==1.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->relbench==1.0.0->relbench[full]==1.0.0) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->relbench==1.0.0->relbench[full]==1.0.0) (4.3.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pooch->relbench==1.0.0->relbench[full]==1.0.0) (24.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch->relbench==1.0.0->relbench[full]==1.0.0) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->relbench==1.0.0->relbench[full]==1.0.0) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->relbench==1.0.0->relbench[full]==1.0.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->relbench==1.0.0->relbench[full]==1.0.0) (3.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric->relbench[full]==1.0.0) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric->relbench[full]==1.0.0) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric->relbench[full]==1.0.0) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric->relbench[full]==1.0.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric->relbench[full]==1.0.0) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->relbench==1.0.0->relbench[full]==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->relbench==1.0.0->relbench[full]==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->relbench==1.0.0->relbench[full]==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->relbench==1.0.0->relbench[full]==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->relbench==1.0.0->relbench[full]==1.0.0) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->relbench[full]==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->relbench[full]==1.0.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->relbench[full]==1.0.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->relbench[full]==1.0.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->relbench[full]==1.0.0) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->relbench[full]==1.0.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric->relbench[full]==1.0.0) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric->relbench[full]==1.0.0) (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch_frame>=0.2.3->relbench[full]==1.0.0) (1.3.0)\n",
            "Found existing installation: pyg-lib 0.4.0+pt24cpu\n",
            "Uninstalling pyg-lib-0.4.0+pt24cpu:\n",
            "  Successfully uninstalled pyg-lib-0.4.0+pt24cpu\n",
            "Found existing installation: torch 2.6.0\n",
            "Uninstalling torch-2.6.0:\n",
            "  Successfully uninstalled torch-2.6.0\n",
            "Collecting torch==2.6.0\n",
            "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
            "Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-2.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "75acab29fdf44371bed1b2d3aaca37b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/pyg-team/pyg-lib.git\n",
            "  Cloning https://github.com/pyg-team/pyg-lib.git to /tmp/pip-req-build-nfebyd35\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pyg-lib.git /tmp/pip-req-build-nfebyd35\n",
            "  Resolved https://github.com/pyg-team/pyg-lib.git to commit 149b4cc3b9a9ca6abd14690a8aca4af31af0ee4c\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyg_lib\n",
            "  Building wheel for pyg_lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyg_lib: filename=pyg_lib-0.4.0-cp311-cp311-linux_x86_64.whl size=4791463 sha256=97ea93e98fca354ac06e6d7ea2a9c0590aa1cd8b7e1cdcd005704873477c3077\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jiwjn4v3/wheels/6e/86/cc/7b01a1bebb7ed0c9e95b8b7d590e91c052363b9f1ebf446298\n",
            "Successfully built pyg_lib\n",
            "Installing collected packages: pyg_lib\n",
            "Successfully installed pyg_lib-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "\n",
        "!pip install pytorch_frame[full]==1.2.2\n",
        "!pip install relbench[full]==1.0.0\n",
        "!pip uninstall -y pyg_lib torch  # Uninstall current versions\n",
        "!pip install torch==2.6.0  # Reinstall your desired PyTorch version\n",
        "!pip install --no-cache-dir git+https://github.com/pyg-team/pyg-lib.git # Install pyg-lib; --no-cache-dir ensures a fresh install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F454ta1Zg0Oq",
        "outputId": "809534af-9ce3-48cb-96a5-9d00d5ff0cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_scatter/_scatter_cpu.so: undefined symbol: _ZN2at4_ops16div__Tensor_mode4callERNS_6TensorERKS2_St8optionalIN3c1017basic_string_viewIcEEE\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_spline_conv/_basis_cpu.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.11/dist-packages/torch_sparse/_spmm_cpu.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.tasks import get_task\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import torch_geometric\n",
        "import torch_frame\n",
        "from torch_geometric.seed import seed_everything\n",
        "from relbench.modeling.utils import get_stype_proposal\n",
        "from collections import defaultdict\n",
        "import requests\n",
        "from io import StringIO\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "import pyg_lib\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXgWzyzyyqZa"
      },
      "source": [
        "# Dataset and task creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6DWB-Kf6nl2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d64655b-37c5-4cf9-b116-90a0e25536b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'rel-f1/db.zip' from 'https://relbench.stanford.edu/download/rel-f1/db.zip' to '/root/.cache/relbench'.\n",
            "100%|███████████████████████████████████████| 704k/704k [00:00<00:00, 99.9MB/s]\n",
            "Unzipping contents of '/root/.cache/relbench/rel-f1/db.zip' to '/root/.cache/relbench/rel-f1/.'\n",
            "Downloading file 'rel-f1/tasks/driver-position.zip' from 'https://relbench.stanford.edu/download/rel-f1/tasks/driver-position.zip' to '/root/.cache/relbench'.\n",
            "100%|█████████████████████████████████████| 36.5k/36.5k [00:00<00:00, 39.3MB/s]\n",
            "Unzipping contents of '/root/.cache/relbench/rel-f1/tasks/driver-position.zip' to '/root/.cache/relbench/rel-f1/tasks/.'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Loading Database object from /root/.cache/relbench/rel-f1/db...\n",
            "Done in 0.15 seconds.\n"
          ]
        }
      ],
      "source": [
        "dataset = get_dataset(\"rel-f1\", download=True)\n",
        "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
        "\n",
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")\n",
        "\n",
        "out_channels = 1\n",
        "# one because we are estimating one single value.\n",
        "loss_fn = L1Loss()\n",
        "# this is the mae loss and is used when have regressions tasks.\n",
        "tune_metric = \"mae\"\n",
        "higher_is_better = False\n",
        "\n",
        "seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "root_dir = \"./data\"\n",
        "\n",
        "db = dataset.get_db()\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "#this is used to get the stype of the columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnBtAMChyqZb"
      },
      "source": [
        "# Embedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QQHYmgIxkX1j"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from typing import List, Optional\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from torch import Tensor\n",
        "\n",
        "\n",
        "# class GloveTextEmbedding:\n",
        "#     def __init__(self, device: Optional[torch.device\n",
        "#                                        ] = None):\n",
        "#         self.model = SentenceTransformer(\n",
        "#             \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "#             device=device,\n",
        "#         )\n",
        "\n",
        "#     def __call__(self, sentences: List[str]) -> Tensor:\n",
        "#         return torch.from_numpy(self.model.encode(sentences))\n",
        "\n",
        "\n",
        "class LightweightGloveEmbedder:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device\n",
        "        self.embeddings = defaultdict(lambda: np.zeros(300))\n",
        "        self._load_embeddings()\n",
        "\n",
        "    def _load_embeddings(self):\n",
        "        try:\n",
        "            #(senza bisogno di estrarre zip\n",
        "            url = \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt\"\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            for line in StringIO(response.text):\n",
        "                parts = line.split()\n",
        "                word = parts[0]\n",
        "                vector = np.array(parts[1:], dtype=np.float32)\n",
        "                self.embeddings[word] = vector\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Couldn't load GloVe embeddings ({str(e)}). Using zero vectors.\")\n",
        "\n",
        "    def __call__(self, sentences):\n",
        "        results = []\n",
        "        for text in sentences:\n",
        "            words = text.lower().split()\n",
        "            vectors = [self.embeddings[w] for w in words if w in self.embeddings]\n",
        "            if vectors:\n",
        "                avg_vector = np.mean(vectors, axis=0)\n",
        "            else:\n",
        "                avg_vector = np.zeros(300)\n",
        "            results.append(avg_vector)\n",
        "\n",
        "        tensor = torch.tensor(np.array(results), dtype=torch.float32)\n",
        "        return tensor.to(self.device) if self.device else tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-BBpUrakdwY",
        "outputId": "d79b1a46-01f5-424e-e0f7-b711048229ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Couldn't load GloVe embeddings (404 Client Error: Not Found for url: https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt). Using zero vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_frame/data/stats.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  ser = pd.to_datetime(ser, format=time_format)\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00,  7.38it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/data/mapper.py:291: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  ser = pd.to_datetime(ser, format=self.format, errors='coerce')\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 623.11it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 1160.17it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 881.43it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 753.05it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 640.57it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 331.41it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 891.84it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 598.93it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 1106.68it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 1229.28it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 1467.05it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 1326.05it/s]\n"
          ]
        }
      ],
      "source": [
        "text_embedder_cfg = TextEmbedderConfig(\n",
        "    text_embedder=LightweightGloveEmbedder(device=device), batch_size=256\n",
        ")\n",
        "\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    #Solution if not working: !pip install --upgrade torch torchvision transformers\n",
        "    db,\n",
        "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
        "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
        "    cache_dir=os.path.join(\n",
        "        root_dir, f\"rel-f1_materialized_cache\"\n",
        "    ),  # store materialized graph for convenience\n",
        ")# create a graph how relbench requires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HUHVG-g6lM-b"
      },
      "outputs": [],
      "source": [
        "loader_dict = {}\n",
        "\n",
        "for split, table in [\n",
        "    (\"train\", train_table),\n",
        "    (\"val\", val_table),\n",
        "    (\"test\", test_table),\n",
        "]:\n",
        "    table_input = get_node_train_table_input(\n",
        "        table=table,\n",
        "        task=task,\n",
        "    )#notice that table_input is an object with three elements: nodes, time and transform.\n",
        "    #nodes contains the input nodes\n",
        "    #time contains the time for each node\n",
        "    #transform is the tranformation to be applied to nodes\n",
        "    entity_table = table_input.nodes[0]\n",
        "    #we need to populate the loader_dict with three elements: \"train\", \"val\", and \"test\".\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=[\n",
        "            128 for i in range(2)\n",
        "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.nodes,\n",
        "        input_time=table_input.time,\n",
        "        transform=table_input.transform,\n",
        "        batch_size=512,\n",
        "        temporal_strategy=\"uniform\",\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=0,\n",
        "        persistent_workers=False,\n",
        "    )#this is the loader for grapg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IazPBkg6yqZc"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "u3m3jEqClQnw"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData, #notice that \"data2 is the graph we created with function make_pkey_fkey_graph\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        # List of node types to add shallow embeddings to input\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        # ID awareness\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "        self.gnn = HeteroGraphSAGE(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            aggr=aggr,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,#one, since we are doing regressio\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        #takes the timestamp of the nodes for which we want to make predictions\n",
        "        #not the neighbours, but the nodes we want to make prediction for.\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        #this creates a dictionar for all the nodes: each nodes has its\n",
        "        #embedding\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "        #this add the temporal information to the node using the\n",
        "        #HeteroTemporalEncoder\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "        #add some other shallow embedder\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,#feature of nodes\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )#apply the gnn\n",
        "\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])#final prediction\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        # Add ID-awareness to the root node\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=3,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"sum\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl-6So7Llb-p"
      },
      "source": [
        "We also need standard train/test loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SAHRIr15lVs6"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer) -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bYR2O8s8yqZe"
      },
      "outputs": [],
      "source": [
        "def rmse(true, pred):\n",
        "    \"\"\"Calculate the Root Mean Squared Error (RMSE).\"\"\"\n",
        "    return np.sqrt(np.mean((true - pred)**2)) # Calculate RMSE manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qZOOyAblHwI4"
      },
      "outputs": [],
      "source": [
        "def custom_evaluate(pred: np.ndarray, target_table, metrics) -> dict:\n",
        "    \"\"\"Custom evaluation function to replace task.evaluate.\"\"\"\n",
        "\n",
        "    # Extract target values from the target table\n",
        "    target = target_table.df[task.target_col].to_numpy()\n",
        "\n",
        "    # Check for length mismatch\n",
        "    if len(pred) != len(target):\n",
        "        raise ValueError(\n",
        "            f\"The length of pred and target must be the same (got \"\n",
        "            f\"{len(pred)} and {len(target)}, respectively).\"\n",
        "        )\n",
        "\n",
        "    # Calculate metrics\n",
        "    results = {}\n",
        "    for metric_fn in metrics:\n",
        "        if metric_fn.__name__ == \"rmse\":  # Handle RMSE specifically\n",
        "            results[\"rmse\"] = np.sqrt(np.mean((target - pred)**2))\n",
        "        else:  # Handle other metrics (if any)\n",
        "            results[metric_fn.__name__] = metric_fn(target, pred)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kHvu7pUqyqZf"
      },
      "outputs": [],
      "source": [
        "def training_function(model, optimizer, epochs):\n",
        "    state_dict = None\n",
        "    best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, optimizer)\n",
        "        val_pred = test(model, loader_dict[\"val\"])\n",
        "        #val_metrics = task.evaluate(val_pred, val_table)\n",
        "        val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "        #print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "        if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "        ):\n",
        "            best_val_metric = val_metrics[tune_metric]\n",
        "            state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "    print(f\"Best Val metrics for parameters {optimizer}, are: {val_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKbFTeSTyqZf"
      },
      "source": [
        "## Cross validation cycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3zOIYrr2yqZf"
      },
      "outputs": [],
      "source": [
        "# #cross validation cycle:\n",
        "# #possible learning rates: [0.01, 0.001, 0.0001, 0.00001]\n",
        "# #possible batch sizes: [64, 256, 512]\n",
        "# #possible number of layers: [1, 2, 3]\n",
        "# #possible weight decay: [0.0001, 0.001, 0.01]\n",
        "\n",
        "# for lr in [0.01, 0.001, 0.0001, 0.00001]:\n",
        "#     #for batch_size in [64, 256, 512]:\n",
        "#         for num_layers in [1, 2, 3]:\n",
        "#             for weight_decay in [0.0001, 0.001, 0.01]:\n",
        "#                 model = Model(\n",
        "#                     data=data,\n",
        "#                     col_stats_dict=col_stats_dict,\n",
        "#                     num_layers=num_layers,\n",
        "#                     channels=128,\n",
        "#                     out_channels=1,\n",
        "#                     aggr=\"sum\",\n",
        "#                     norm=\"batch_norm\",\n",
        "#                 ).to(device)\n",
        "#                 print(f\"Training with lr={lr}, num_layers={num_layers}, weight_decay={weight_decay}\")\n",
        "#                 optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "#                 training_function(model, optimizer, epochs=30) # Set epochs to a smaller number for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgSQVotVyqZf"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF3W68Eqlew_",
        "outputId": "c18de4bf-3c25-4156-fa4b-fd1948b908b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Train loss: 7.653547952883071, Val metrics: {'r2': -0.5878122273877961, 'mae': 4.650918867688379, 'rmse': np.float64(5.841842724869911)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02, Train loss: 5.680439187746855, Val metrics: {'r2': -0.21397099582188472, 'mae': 4.0912135615377485, 'rmse': np.float64(5.1080418290222624)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03, Train loss: 5.5071210923265905, Val metrics: {'r2': -0.018746245785570714, 'mae': 3.8297912324995855, 'rmse': np.float64(4.679325973570707)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 04, Train loss: 5.4787103982958945, Val metrics: {'r2': 0.05326881836862851, 'mae': 3.7162961609457525, 'rmse': np.float64(4.510904474102544)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05, Train loss: 5.447459895867046, Val metrics: {'r2': 0.02268161083010789, 'mae': 3.696600859724209, 'rmse': np.float64(4.583194888463802)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 06, Train loss: 5.392011953459064, Val metrics: {'r2': -0.00864593170075123, 'mae': 3.739943628432198, 'rmse': np.float64(4.656071707621786)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 07, Train loss: 5.382620308713658, Val metrics: {'r2': 0.007905171964710411, 'mae': 3.685646151668164, 'rmse': np.float64(4.617712417997115)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 08, Train loss: 5.34325357790555, Val metrics: {'r2': 0.09922191067845465, 'mae': 3.5642905885725713, 'rmse': np.float64(4.4000660574010295)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 09, Train loss: 5.085908324769979, Val metrics: {'r2': 0.24415899459845192, 'mae': 3.238865952119082, 'rmse': np.float64(4.030561148116252)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Train loss: 4.882049611602296, Val metrics: {'r2': 0.23105726199178056, 'mae': 3.2408380487399975, 'rmse': np.float64(4.065343897301294)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11, Train loss: 4.884361701572756, Val metrics: {'r2': 0.2197268742318952, 'mae': 3.2543635739751395, 'rmse': np.float64(4.095185833729141)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12, Train loss: 4.834859722687161, Val metrics: {'r2': 0.1879351412981214, 'mae': 3.3620108410128773, 'rmse': np.float64(4.177780786412465)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13, Train loss: 4.87627308694657, Val metrics: {'r2': 0.2082102961514849, 'mae': 3.3438920849868277, 'rmse': np.float64(4.125296940028729)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14, Train loss: 4.813648308649425, Val metrics: {'r2': 0.15160666395832245, 'mae': 3.48071789751072, 'rmse': np.float64(4.2702068601313)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15, Train loss: 4.7794307285581645, Val metrics: {'r2': 0.24431363361817382, 'mae': 3.2785517182920323, 'rmse': np.float64(4.030148816750721)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16, Train loss: 4.7344598780378275, Val metrics: {'r2': 0.22171943284363893, 'mae': 3.279638192489614, 'rmse': np.float64(4.089953618489393)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17, Train loss: 4.78140172730608, Val metrics: {'r2': 0.24533563026455374, 'mae': 3.251657670389913, 'rmse': np.float64(4.0274226910222355)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18, Train loss: 4.716400487109765, Val metrics: {'r2': 0.21798462116734352, 'mae': 3.27110063212668, 'rmse': np.float64(4.099755305280118)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19, Train loss: 4.690709144208921, Val metrics: {'r2': 0.16472546991478632, 'mae': 3.3618873133050977, 'rmse': np.float64(4.23706287812596)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20, Train loss: 4.7649578651485545, Val metrics: {'r2': 0.23639433014327704, 'mae': 3.252438332577427, 'rmse': np.float64(4.0512109871463835)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21, Train loss: 4.742637299602022, Val metrics: {'r2': 0.23286592893104874, 'mae': 3.232541007078243, 'rmse': np.float64(4.060559937728024)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22, Train loss: 4.691842283000406, Val metrics: {'r2': 0.2435586450526792, 'mae': 3.2365405139400707, 'rmse': np.float64(4.032161527851489)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23, Train loss: 4.752046694295544, Val metrics: {'r2': 0.2515802809232124, 'mae': 3.255070652767429, 'rmse': np.float64(4.010725141586876)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24, Train loss: 4.670426126232119, Val metrics: {'r2': 0.2550243454249608, 'mae': 3.159858533327947, 'rmse': np.float64(4.001486258822686)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25, Train loss: 4.692760404701699, Val metrics: {'r2': 0.13008587308789, 'mae': 3.51505916349555, 'rmse': np.float64(4.324027839572299)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26, Train loss: 4.70412212938938, Val metrics: {'r2': 0.2527341565797565, 'mae': 3.18689818659383, 'rmse': np.float64(4.0076321824348)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27, Train loss: 4.660355804207404, Val metrics: {'r2': 0.26554091058931495, 'mae': 3.1818920643869526, 'rmse': np.float64(3.9731420691614834)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28, Train loss: 4.656064531266665, Val metrics: {'r2': 0.29305173213577396, 'mae': 3.078202923154863, 'rmse': np.float64(3.8980203942199716)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29, Train loss: 4.652090275254039, Val metrics: {'r2': 0.23662858597651393, 'mae': 3.2082980056563932, 'rmse': np.float64(4.050589532488468)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30, Train loss: 4.638691935045966, Val metrics: {'r2': 0.2882387680119203, 'mae': 3.087461065433785, 'rmse': np.float64(3.911266914313531)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31, Train loss: 4.644512030193186, Val metrics: {'r2': 0.23602645233238118, 'mae': 3.19915257717023, 'rmse': np.float64(4.052186733681614)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32, Train loss: 4.671523707034235, Val metrics: {'r2': 0.09836739975539999, 'mae': 3.461753953705649, 'rmse': np.float64(4.402152594185094)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33, Train loss: 4.697793870744459, Val metrics: {'r2': 0.2900501856287103, 'mae': 3.0909394438137747, 'rmse': np.float64(3.9062866969497616)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34, Train loss: 4.633626884955392, Val metrics: {'r2': 0.21649514843189566, 'mae': 3.2679503498829123, 'rmse': np.float64(4.1036577661475535)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 35, Train loss: 4.663259523052122, Val metrics: {'r2': 0.22047893011543507, 'mae': 3.267533314538623, 'rmse': np.float64(4.093211812732703)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 36, Train loss: 4.666318968544227, Val metrics: {'r2': 0.22383165138111805, 'mae': 3.2210422756676684, 'rmse': np.float64(4.084399872473593)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 37, Train loss: 4.606039126831366, Val metrics: {'r2': 0.26761588717882834, 'mae': 3.138246888547399, 'rmse': np.float64(3.9675256856536962)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 38, Train loss: 4.5940702690560595, Val metrics: {'r2': 0.1979276607652456, 'mae': 3.2819313231514706, 'rmse': np.float64(4.15199726968911)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 39, Train loss: 4.579487446409159, Val metrics: {'r2': 0.3047797435356199, 'mae': 3.0730831110565044, 'rmse': np.float64(3.865551809216631)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 40, Train loss: 4.559401330636937, Val metrics: {'r2': 0.28247612303452874, 'mae': 3.0582182010174117, 'rmse': np.float64(3.9270684248230476)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 41, Train loss: 4.555778240015503, Val metrics: {'r2': 0.2908939982395049, 'mae': 3.0519258853349194, 'rmse': np.float64(3.9039645933933294)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 42, Train loss: 4.593263908822824, Val metrics: {'r2': 0.2975213532636355, 'mae': 3.094715863255238, 'rmse': np.float64(3.885678401988499)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 43, Train loss: 4.571785233284057, Val metrics: {'r2': 0.2830515344607878, 'mae': 3.1052196953084845, 'rmse': np.float64(3.9254934714801304)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 44, Train loss: 4.576769506277118, Val metrics: {'r2': 0.24381457450376232, 'mae': 3.1741555981581895, 'rmse': np.float64(4.0314793624858325)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 45, Train loss: 4.61923657387483, Val metrics: {'r2': 0.31234809259779095, 'mae': 3.0007245512906917, 'rmse': np.float64(3.844453529073685)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 46, Train loss: 4.5806011077494935, Val metrics: {'r2': 0.2843439209241173, 'mae': 3.0944992704397847, 'rmse': np.float64(3.921953786816319)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 47, Train loss: 4.545830015558437, Val metrics: {'r2': 0.21757456798000607, 'mae': 3.180078208581877, 'rmse': np.float64(4.100830026735815)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 48, Train loss: 4.539617798655653, Val metrics: {'r2': 0.17139441459622884, 'mae': 3.2996071061215244, 'rmse': np.float64(4.220114339281838)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 49, Train loss: 4.5761471888722465, Val metrics: {'r2': 0.31553805747415775, 'mae': 3.0262880088969237, 'rmse': np.float64(3.835526099920175)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50, Train loss: 4.523356404157992, Val metrics: {'r2': 0.31494855388095366, 'mae': 3.044381129877044, 'rmse': np.float64(3.837177447967623)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 51, Train loss: 4.531880378083352, Val metrics: {'r2': 0.2837402192855307, 'mae': 3.01179190522922, 'rmse': np.float64(3.9236076474365427)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 52, Train loss: 4.547882487497825, Val metrics: {'r2': 0.2828491565804281, 'mae': 3.1237375487465817, 'rmse': np.float64(3.926047470150692)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 53, Train loss: 4.5077822825484155, Val metrics: {'r2': 0.31432196701035175, 'mae': 2.9986219455818373, 'rmse': np.float64(3.838931896842228)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 54, Train loss: 4.619852157338392, Val metrics: {'r2': 0.3062821996998385, 'mae': 3.0233493546286505, 'rmse': np.float64(3.86137258447534)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 55, Train loss: 4.583619236610215, Val metrics: {'r2': 0.30520109590457567, 'mae': 3.0617147070452138, 'rmse': np.float64(3.864380233548712)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 56, Train loss: 4.554905639404293, Val metrics: {'r2': 0.30937167357877937, 'mae': 3.0233266953396334, 'rmse': np.float64(3.8527646739342107)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 57, Train loss: 4.502102659738066, Val metrics: {'r2': 0.2938447701851239, 'mae': 3.054978293200374, 'rmse': np.float64(3.8958334266242463)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 58, Train loss: 4.508422227125272, Val metrics: {'r2': 0.30611069823424075, 'mae': 3.009362559614774, 'rmse': np.float64(3.8618498607776828)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 59, Train loss: 4.501471635464548, Val metrics: {'r2': 0.29748368998245756, 'mae': 3.083104802898032, 'rmse': np.float64(3.885782565607817)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 60, Train loss: 4.4947865744749045, Val metrics: {'r2': 0.3275079468377772, 'mae': 2.9791400980774214, 'rmse': np.float64(3.8018402825071975)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 61, Train loss: 4.470765763283672, Val metrics: {'r2': 0.25632396080803577, 'mae': 3.1326942394157213, 'rmse': np.float64(3.997994424508089)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 62, Train loss: 4.465411654994037, Val metrics: {'r2': 0.27266126204363905, 'mae': 3.138745330251211, 'rmse': np.float64(3.9538359779199506)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 63, Train loss: 4.463979292920367, Val metrics: {'r2': 0.3303996975329556, 'mae': 2.9574006620214717, 'rmse': np.float64(3.793657421184204)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 64, Train loss: 4.483907334135632, Val metrics: {'r2': 0.32416818248966717, 'mae': 2.9997082142011275, 'rmse': np.float64(3.8112690372141027)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 65, Train loss: 4.4705234197711015, Val metrics: {'r2': 0.26732916724177014, 'mae': 3.119399034650468, 'rmse': np.float64(3.9683022299427404)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 66, Train loss: 4.455555748910723, Val metrics: {'r2': 0.2822048411599607, 'mae': 3.100875489394826, 'rmse': np.float64(3.927810728905695)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 67, Train loss: 4.52783695649864, Val metrics: {'r2': 0.32701220318534363, 'mae': 2.990738142723231, 'rmse': np.float64(3.803241333242096)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 68, Train loss: 4.474716993365434, Val metrics: {'r2': 0.30006379863775656, 'mae': 3.059016085021402, 'rmse': np.float64(3.8786404086693533)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 69, Train loss: 4.517927745548843, Val metrics: {'r2': 0.32116031199245354, 'mae': 2.983016993000894, 'rmse': np.float64(3.8197408762463407)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 70, Train loss: 4.444338555273939, Val metrics: {'r2': 0.32219737679453153, 'mae': 2.97113033331627, 'rmse': np.float64(3.816822048008006)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 71, Train loss: 4.451362295597332, Val metrics: {'r2': 0.31034092898785426, 'mae': 2.9898662749336973, 'rmse': np.float64(3.850060162695349)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 72, Train loss: 4.46579667268848, Val metrics: {'r2': 0.23745721524079122, 'mae': 3.1919685017529056, 'rmse': np.float64(4.048390505711419)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 73, Train loss: 4.472618999312296, Val metrics: {'r2': 0.22725880697315848, 'mae': 3.169157554279906, 'rmse': np.float64(4.075372604144457)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 74, Train loss: 4.482645821990414, Val metrics: {'r2': 0.342900072019966, 'mae': 2.947533256655625, 'rmse': np.float64(3.758079814229878)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 75, Train loss: 4.433663337195174, Val metrics: {'r2': 0.2930639640964584, 'mae': 3.080374381282605, 'rmse': np.float64(3.8979866713574753)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 76, Train loss: 4.436550996806755, Val metrics: {'r2': 0.25324918650054995, 'mae': 3.1408137313190427, 'rmse': np.float64(4.00625087598807)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 77, Train loss: 4.471343017177871, Val metrics: {'r2': 0.3549045221157888, 'mae': 2.9210846931518675, 'rmse': np.float64(3.723593713172072)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 78, Train loss: 4.457947912335188, Val metrics: {'r2': 0.3231119834284, 'mae': 2.974586310733854, 'rmse': np.float64(3.8142460258247017)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 79, Train loss: 4.520678194548386, Val metrics: {'r2': 0.3032847011943327, 'mae': 3.0888180886257786, 'rmse': np.float64(3.8697059315589915)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 80, Train loss: 4.434148237271132, Val metrics: {'r2': 0.3270849498844737, 'mae': 3.01043748623065, 'rmse': np.float64(3.8030357717657512)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 81, Train loss: 4.435985397879875, Val metrics: {'r2': 0.3419661066223598, 'mae': 2.9212627617295137, 'rmse': np.float64(3.7607496290053204)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 82, Train loss: 4.477789333806204, Val metrics: {'r2': 0.33218530852469774, 'mae': 3.0039089320736405, 'rmse': np.float64(3.788595805754819)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 83, Train loss: 4.427570954722941, Val metrics: {'r2': 0.31174545407531495, 'mae': 3.0370041291078245, 'rmse': np.float64(3.8461377448767906)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 84, Train loss: 4.432682711886477, Val metrics: {'r2': 0.2928148009914153, 'mae': 3.08252862619414, 'rmse': np.float64(3.8986735431882416)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 85, Train loss: 4.4080226683351125, Val metrics: {'r2': 0.3347139914298086, 'mae': 2.940426940510252, 'rmse': np.float64(3.7814162366266686)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 86, Train loss: 4.427316408452933, Val metrics: {'r2': 0.31564605011982494, 'mae': 3.0042071620862165, 'rmse': np.float64(3.8352235082603605)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 87, Train loss: 4.395016644635361, Val metrics: {'r2': 0.32377701116849633, 'mae': 3.017737093207513, 'rmse': np.float64(3.8123718585382607)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 88, Train loss: 4.4124836568526575, Val metrics: {'r2': 0.3211673854604241, 'mae': 3.0469139488999972, 'rmse': np.float64(3.8197209754615122)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 89, Train loss: 4.464020033226898, Val metrics: {'r2': 0.1622891023690386, 'mae': 3.3218854201500947, 'rmse': np.float64(4.243237809474956)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 90, Train loss: 4.424944135657448, Val metrics: {'r2': 0.3375702888655516, 'mae': 2.975000874042192, 'rmse': np.float64(3.773290056880414)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 91, Train loss: 4.3871355499498925, Val metrics: {'r2': 0.332910947230463, 'mae': 2.979815576230994, 'rmse': np.float64(3.786536926999719)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 92, Train loss: 4.400691286535147, Val metrics: {'r2': 0.3151336889683152, 'mae': 3.057138600728475, 'rmse': np.float64(3.836658914513904)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 93, Train loss: 4.420256914363745, Val metrics: {'r2': 0.22295616462255108, 'mae': 3.1961981824978083, 'rmse': np.float64(4.086702742868424)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 94, Train loss: 4.39517679819721, Val metrics: {'r2': 0.3310301014765249, 'mae': 2.986493525508251, 'rmse': np.float64(3.791871206526735)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 95, Train loss: 4.401414564307482, Val metrics: {'r2': 0.2838326613504526, 'mae': 3.121576907336911, 'rmse': np.float64(3.92335444454402)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 96, Train loss: 4.3994773736531725, Val metrics: {'r2': 0.34976591932706635, 'mae': 2.9419652483984082, 'rmse': np.float64(3.738394713096301)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 97, Train loss: 4.408967588758142, Val metrics: {'r2': 0.34429265530407105, 'mae': 2.976545807577884, 'rmse': np.float64(3.754095477420126)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 98, Train loss: 4.3666153700739105, Val metrics: {'r2': 0.337863611965979, 'mae': 3.0060244209223295, 'rmse': np.float64(3.7724545601714796)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 99, Train loss: 4.40720111162858, Val metrics: {'r2': 0.31391050911906415, 'mae': 2.9965774064551374, 'rmse': np.float64(3.8400835466362433)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100, Train loss: 4.427245800533215, Val metrics: {'r2': 0.3276686410764936, 'mae': 2.998012019445996, 'rmse': np.float64(3.801386024105495)}\n",
            "Best Val metrics: {'r2': 0.35825753544521655, 'mae': 2.916818310502536, 'rmse': np.float64(3.7139040426167584)}\n"
          ]
        }
      ],
      "source": [
        "model = Model(\n",
        "                    data=data,\n",
        "                    col_stats_dict=col_stats_dict,\n",
        "                    num_layers=2,\n",
        "                    channels=128,\n",
        "                    out_channels=1,\n",
        "                    aggr=\"mean\",\n",
        "                    norm=\"batch_norm\",\n",
        "                ).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
        "epochs = 100\n",
        "state_dict = None\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(model, optimizer)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    #val_metrics = task.evaluate(val_pred, val_table)\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "val_pred = test(model, loader_dict[\"val\"])\n",
        "val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "print(f\"Best Val metrics: {val_metrics}\")\n",
        "\n",
        "# test_pred = test(loader_dict[\"test\"])\n",
        "# test_metrics = custom_evaluate(test_pred, test_table, task.metrics)\n",
        "# print(f\"Best test metrics: {test_metrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2_Dr5oFyqZg"
      },
      "outputs": [],
      "source": [
        "#test_pred = test(loader_dict[\"test\"])\n",
        "#test_metrics = custom_evaluate(test_pred, test_table, task.metrics)\n",
        "#print(f\"Best test metrics: {test_metrics}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}