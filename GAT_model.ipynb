{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea-1704/Pytorch_Geometric_tutorial/blob/main/train_model_baseline_f1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNziUzq9nTdU",
        "outputId": "6716be7d-c2cb-439e-d8e6-674183246c2a"
      },
      "outputs": [],
      "source": [
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "\n",
        "# !pip install pytorch_frame[full]==1.2.2\n",
        "# !pip install relbench[full]==1.0.0\n",
        "# !pip uninstall -y pyg_lib torch  # Uninstall current versions\n",
        "# !pip install torch==2.6.0  # Reinstall your desired PyTorch version\n",
        "# !pip install --no-cache-dir git+https://github.com/pyg-team/pyg-lib.git # Install pyg-lib; --no-cache-dir ensures a fresh install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F454ta1Zg0Oq",
        "outputId": "4843dbd5-7637-430f-e320-2d0f62bfe094"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.tasks import get_task\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import torch_geometric\n",
        "import torch_frame\n",
        "from torch_geometric.seed import seed_everything\n",
        "from relbench.modeling.utils import get_stype_proposal\n",
        "from collections import defaultdict\n",
        "import requests\n",
        "from io import StringIO\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "import pyg_lib\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset and task creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6DWB-Kf6nl2y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Loading Database object from C:\\Users\\andrea\\AppData\\Local\\relbench\\relbench\\Cache/rel-f1/db...\n",
            "Done in 0.10 seconds.\n"
          ]
        }
      ],
      "source": [
        "dataset = get_dataset(\"rel-f1\", download=True)\n",
        "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
        "\n",
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")\n",
        "\n",
        "out_channels = 1\n",
        "# one because we are estimating one single value.\n",
        "loss_fn = L1Loss()\n",
        "# this is the mae loss and is used when have regressions tasks.\n",
        "tune_metric = \"mae\"\n",
        "higher_is_better = False\n",
        "\n",
        "seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device) \n",
        "root_dir = \"./data\"\n",
        "\n",
        "db = dataset.get_db()\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "#this is used to get the stype of the columns "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Embedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QQHYmgIxkX1j"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from typing import List, Optional\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from torch import Tensor\n",
        "\n",
        "\n",
        "# class GloveTextEmbedding:\n",
        "#     def __init__(self, device: Optional[torch.device\n",
        "#                                        ] = None):\n",
        "#         self.model = SentenceTransformer(\n",
        "#             \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "#             device=device,\n",
        "#         )\n",
        "\n",
        "#     def __call__(self, sentences: List[str]) -> Tensor:\n",
        "#         return torch.from_numpy(self.model.encode(sentences))\n",
        "\n",
        "\n",
        "class LightweightGloveEmbedder:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device\n",
        "        self.embeddings = defaultdict(lambda: np.zeros(300))\n",
        "        self._load_embeddings()\n",
        "\n",
        "    def _load_embeddings(self):\n",
        "        try:\n",
        "            #(senza bisogno di estrarre zip\n",
        "            url = \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt\"\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            for line in StringIO(response.text):\n",
        "                parts = line.split()\n",
        "                word = parts[0]\n",
        "                vector = np.array(parts[1:], dtype=np.float32)\n",
        "                self.embeddings[word] = vector\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Couldn't load GloVe embeddings ({str(e)}). Using zero vectors.\")\n",
        "\n",
        "    def __call__(self, sentences):\n",
        "        results = []\n",
        "        for text in sentences:\n",
        "            words = text.lower().split()\n",
        "            vectors = [self.embeddings[w] for w in words if w in self.embeddings]\n",
        "            if vectors:\n",
        "                avg_vector = np.mean(vectors, axis=0)\n",
        "            else:\n",
        "                avg_vector = np.zeros(300)\n",
        "            results.append(avg_vector)\n",
        "\n",
        "        tensor = torch.tensor(np.array(results), dtype=torch.float32)\n",
        "        return tensor.to(self.device) if self.device else tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-BBpUrakdwY",
        "outputId": "520fd668-67b2-455a-86ea-c18a1643e095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Couldn't load GloVe embeddings (404 Client Error: Not Found for url: https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt). Using zero vectors.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch_frame\\utils\\io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "c:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch_frame\\utils\\io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "c:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch_frame\\utils\\io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "c:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch_frame\\utils\\io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "c:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch_frame\\utils\\io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "c:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch_frame\\utils\\io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "c:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch_frame\\utils\\io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n"
          ]
        }
      ],
      "source": [
        "text_embedder_cfg = TextEmbedderConfig(\n",
        "    text_embedder=LightweightGloveEmbedder(device=device), batch_size=256\n",
        ")\n",
        "\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    #Solution if not working: !pip install --upgrade torch torchvision transformers\n",
        "    db,\n",
        "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
        "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
        "    cache_dir=os.path.join(\n",
        "        root_dir, f\"rel-f1_materialized_cache\"\n",
        "    ),  # store materialized graph for convenience\n",
        ")# create a graph how relbench requires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HUHVG-g6lM-b"
      },
      "outputs": [],
      "source": [
        "loader_dict = {}\n",
        "\n",
        "for split, table in [\n",
        "    (\"train\", train_table),\n",
        "    (\"val\", val_table),\n",
        "    (\"test\", test_table),\n",
        "]:\n",
        "    table_input = get_node_train_table_input(\n",
        "        table=table,\n",
        "        task=task,\n",
        "    )#notice that table_input is an object with three elements: nodes, time and transform.\n",
        "    #nodes contains the input nodes\n",
        "    #time contains the time for each node\n",
        "    #transform is the tranformation to be applied to nodes\n",
        "    entity_table = table_input.nodes[0]\n",
        "    #we need to populate the loader_dict with three elements: \"train\", \"val\", and \"test\".\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=[\n",
        "            128 for i in range(2)\n",
        "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.nodes,\n",
        "        input_time=table_input.time,\n",
        "        transform=table_input.transform,\n",
        "        batch_size=512,\n",
        "        temporal_strategy=\"uniform\",\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=0,\n",
        "        persistent_workers=False,\n",
        "    )#this is the loader for grapg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GAT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.nn import HeteroConv, GATConv\n",
        "\n",
        "class HeteroGAT(torch.nn.Module):\n",
        "    def __init__(self, node_types, edge_types, channels, heads=8, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.edge_types = edge_types\n",
        "        #per ogni layer andiamoa a creare un HeteroConv che contiene \n",
        "        #tanti GATConv (che sono giÃ  implementati) quanti sono gli \n",
        "        #edge type.\n",
        "        for i in range(num_layers):\n",
        "            conv = HeteroConv(\n",
        "                {\n",
        "                    edge_type: GATConv(\n",
        "                        (-1, -1), channels, heads=heads, concat=False, add_self_loops=False\n",
        "                    )\n",
        "                    for edge_type in edge_types\n",
        "                },\n",
        "                aggr=\"sum\",\n",
        "            )\n",
        "            self.convs.append(conv)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, *args, **kwargs):\n",
        "        for conv in self.convs:\n",
        "            x_dict = conv(x_dict, edge_index_dict)\n",
        "        return x_dict\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            for edge_type in self.edge_types:\n",
        "                conv.convs[edge_type].reset_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How does it works?\n",
        "\n",
        "It's pretty simple: for each layer of the network we are creating an HeteroConv layer, which can be seen as a wrapper of GNN layers. Then, for each edge_type in that layer we are creating a GAT layer.\n",
        "\n",
        "The reason why we need a different GAT layer for each different edge type of a given layer is that each layer requires to be considered separately for it's semantic difference with all the others. \n",
        "\n",
        "So each of the edge type requires its own attention scores.\n",
        "\n",
        "NB:\n",
        "\n",
        "When we do something like:\n",
        "~~~python\n",
        "edge_type: GATConv(\n",
        "    (-1, -1), channels, heads=heads, concat=False, add_self_loops=False\n",
        ")\n",
        "~~~\n",
        "\n",
        "The \"(-1, -1)\" refers to the dimension of the input channels. In this case we are using 'lazy initialization': PyTorch Geometric will automatically infer the in_channels during the first forward() call by reading the actual dimensions of the source and destination node embeddings.\n",
        "\n",
        "This is especially useful in heterogeneous graphs, where dimensions may vary across different types (or be decided dynamically)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u3m3jEqClQnw"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData, #notice that \"data2 is the graph we created with function make_pkey_fkey_graph\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        # List of node types to add shallow embeddings to input\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        # ID awareness\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "        self.gnn = HeteroGAT(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            heads=8,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,#one, since we are doing regressio\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData, \n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        #takes the timestamp of the nodes for which we want to make predictions\n",
        "        #not the neighbours, but the nodes we want to make prediction for.\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        #this creates a dictionar for all the nodes: each nodes has its\n",
        "        #embedding\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "        #this add the temporal information to the node using the \n",
        "        #HeteroTemporalEncoder\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "        #add some other shallow embedder\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,#feature of nodes\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )#apply the gnn\n",
        "\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])#final prediction\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        # Add ID-awareness to the root node\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=2,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"sum\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl-6So7Llb-p"
      },
      "source": [
        "We also need standard train/test loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SAHRIr15lVs6"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer) -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rmse(true, pred):\n",
        "    \"\"\"Calculate the Root Mean Squared Error (RMSE).\"\"\"\n",
        "    return np.sqrt(np.mean((true - pred)**2)) # Calculate RMSE manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qZOOyAblHwI4"
      },
      "outputs": [],
      "source": [
        "def custom_evaluate(pred: np.ndarray, target_table, metrics) -> dict:\n",
        "    \"\"\"Custom evaluation function to replace task.evaluate.\"\"\"\n",
        "\n",
        "    # Extract target values from the target table\n",
        "    target = target_table.df[task.target_col].to_numpy()\n",
        "\n",
        "    # Check for length mismatch\n",
        "    if len(pred) != len(target):\n",
        "        raise ValueError(\n",
        "            f\"The length of pred and target must be the same (got \"\n",
        "            f\"{len(pred)} and {len(target)}, respectively).\"\n",
        "        )\n",
        "\n",
        "    # Calculate metrics\n",
        "    results = {}\n",
        "    for metric_fn in metrics:\n",
        "        if metric_fn.__name__ == \"rmse\":  # Handle RMSE specifically\n",
        "            results[\"rmse\"] = np.sqrt(np.mean((target - pred)**2))\n",
        "        else:  # Handle other metrics (if any)\n",
        "            results[metric_fn.__name__] = metric_fn(target, pred)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training_function(model, optimizer, epochs):\n",
        "    state_dict = None\n",
        "    best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, optimizer)\n",
        "        val_pred = test(model, loader_dict[\"val\"])\n",
        "        #val_metrics = task.evaluate(val_pred, val_table)\n",
        "        val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "        #print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "        if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "        ):\n",
        "            best_val_metric = val_metrics[tune_metric]\n",
        "            state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "    print(f\"Best Val metrics for parameters {optimizer}, are: {val_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross validation cycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #cross validation cycle:\n",
        "# #possible learning rates: [0.01, 0.001, 0.0001, 0.00001]\n",
        "# #possible batch sizes: [64, 256, 512]\n",
        "# #possible number of layers: [1, 2, 3]\n",
        "# #possible weight decay: [0.0001, 0.001, 0.01]\n",
        "\n",
        "# for lr in [0.01, 0.001, 0.0001, 0.00001]:#0.001\n",
        "#     #for batch_size in [64, 256, 512]:\n",
        "#         for num_layers in [1, 2, 3]:#1\n",
        "#             #for weight_decay in [0.0001, 0.001, 0.01]:\n",
        "#                 model = Model(\n",
        "#                     data=data,\n",
        "#                     col_stats_dict=col_stats_dict,\n",
        "#                     num_layers=num_layers,\n",
        "#                     channels=128,\n",
        "#                     out_channels=1,\n",
        "#                     aggr=\"sum\",\n",
        "#                     norm=\"batch_norm\",\n",
        "#                 ).to(device)\n",
        "#                 print(f\"Training with lr={lr}, num_layers={num_layers}\")\n",
        "#                 optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
        "#                 training_function(model, optimizer, epochs=10) # Set epochs to a smaller number for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "yF3W68Eqlew_",
        "outputId": "91ae72b2-0964-4a72-f100-acebbec7c95f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/15 [00:09<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m best_val_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39minf \u001b[38;5;28;01mif\u001b[39;00m higher_is_better \u001b[38;5;28;01melse\u001b[39;00m math\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 16\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     val_pred \u001b[38;5;241m=\u001b[39m test(model, loader_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m#val_metrics = task.evaluate(val_pred, val_table)\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer)\u001b[0m\n\u001b[0;32m      6\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m pred\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m pred\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred\u001b[38;5;241m.\u001b[39mfloat(), batch[entity_table]\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mfloat())\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[8], line 76\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, batch, entity_table)\u001b[0m\n\u001b[0;32m     73\u001b[0m seed_time \u001b[38;5;241m=\u001b[39m batch[entity_table]\u001b[38;5;241m.\u001b[39mseed_time\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m#takes the timestamp of the nodes for which we want to make predictions\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m#not the neighbours, but the nodes we want to make prediction for.\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m#this creates a dictionar for all the nodes: each nodes has its\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m#embedding\u001b[39;00m\n\u001b[0;32m     80\u001b[0m rel_time_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_encoder(\n\u001b[0;32m     81\u001b[0m     seed_time, batch\u001b[38;5;241m.\u001b[39mtime_dict, batch\u001b[38;5;241m.\u001b[39mbatch_dict\n\u001b[0;32m     82\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\relbench\\modeling\\nn.py:83\u001b[0m, in \u001b[0;36mHeteroEncoder.forward\u001b[1;34m(self, tf_dict)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     81\u001b[0m     tf_dict: Dict[NodeType, torch_frame\u001b[38;5;241m.\u001b[39mTensorFrame],\n\u001b[0;32m     82\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[NodeType, Tensor]:\n\u001b[1;32m---> 83\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     84\u001b[0m         node_type: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoders[node_type](tf) \u001b[38;5;28;01mfor\u001b[39;00m node_type, tf \u001b[38;5;129;01min\u001b[39;00m tf_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     85\u001b[0m     }\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_dict\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\relbench\\modeling\\nn.py:84\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     81\u001b[0m     tf_dict: Dict[NodeType, torch_frame\u001b[38;5;241m.\u001b[39mTensorFrame],\n\u001b[0;32m     82\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[NodeType, Tensor]:\n\u001b[0;32m     83\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 84\u001b[0m         node_type: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m node_type, tf \u001b[38;5;129;01min\u001b[39;00m tf_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     85\u001b[0m     }\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_dict\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch_frame\\nn\\models\\resnet.py:202\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, tf)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Flattening the encoder output\u001b[39;00m\n\u001b[0;32m    200\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), math\u001b[38;5;241m.\u001b[39mprod(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]))\n\u001b[1;32m--> 202\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch_frame\\nn\\models\\resnet.py:83\u001b[0m, in \u001b[0;36mFCResidualBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     81\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(x)\n\u001b[0;32m     82\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1 \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[1;32m---> 83\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out)\n\u001b[0;32m     86\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(out)\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\activation.py:104\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\functional.py:1500\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = Model(\n",
        "                    data=data,\n",
        "                    col_stats_dict=col_stats_dict,\n",
        "                    num_layers=1,\n",
        "                    channels=128,\n",
        "                    out_channels=1,\n",
        "                    aggr=\"mean\",\n",
        "                    norm=\"batch_norm\",\n",
        "                ).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
        "epochs = 3\n",
        "state_dict = None\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(model, optimizer)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    #val_metrics = task.evaluate(val_pred, val_table)\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "val_pred = test(model, loader_dict[\"val\"])\n",
        "val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "print(f\"Best Val metrics: {val_metrics}\")\n",
        "\n",
        "task.get_table(\"test\", mask_input_cols=False)\n",
        "test_table = task.get_table(\"test\", mask_input_cols=False)\n",
        "test_pred = test(model,loader_dict[\"test\"])\n",
        "test_metrics = custom_evaluate(test_pred, test_table, task.metrics)\n",
        "print(f\"Best test metrics: {test_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import a predefined model to use it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\andrea\\AppData\\Local\\Temp\\ipykernel_13392\\1326568651.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model_GAT_head2.pth', map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for Model:\n\tMissing key(s) in state_dict: \"encoder.encoders.qualifying.encoder.encoder_dict.categorical.offset\", \"encoder.encoders.qualifying.encoder.encoder_dict.categorical.emb.weight\". \n\tUnexpected key(s) in state_dict: \"encoder.encoders.constructor_standings.encoder.encoder_dict.categorical.offset\", \"encoder.encoders.constructor_standings.encoder.encoder_dict.categorical.emb.weight\". \n\tsize mismatch for encoder.encoders.constructor_standings.encoder.encoder_dict.numerical.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([3, 128]).\n\tsize mismatch for encoder.encoders.constructor_standings.encoder.encoder_dict.numerical.bias: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([3, 128]).\n\tsize mismatch for encoder.encoders.constructor_standings.encoder.encoder_dict.numerical.mean: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for encoder.encoders.constructor_standings.encoder.encoder_dict.numerical.std: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for encoder.encoders.qualifying.encoder.encoder_dict.numerical.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([1, 128]).\n\tsize mismatch for encoder.encoders.qualifying.encoder.encoder_dict.numerical.bias: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([1, 128]).\n\tsize mismatch for encoder.encoders.qualifying.encoder.encoder_dict.numerical.mean: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for encoder.encoders.qualifying.encoder.encoder_dict.numerical.std: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model_GAT_head2.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andrea\\Desktop\\Tesi (GNN)\\Laboratori GNNs\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Model:\n\tMissing key(s) in state_dict: \"encoder.encoders.qualifying.encoder.encoder_dict.categorical.offset\", \"encoder.encoders.qualifying.encoder.encoder_dict.categorical.emb.weight\". \n\tUnexpected key(s) in state_dict: \"encoder.encoders.constructor_standings.encoder.encoder_dict.categorical.offset\", \"encoder.encoders.constructor_standings.encoder.encoder_dict.categorical.emb.weight\". \n\tsize mismatch for encoder.encoders.constructor_standings.encoder.encoder_dict.numerical.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([3, 128]).\n\tsize mismatch for encoder.encoders.constructor_standings.encoder.encoder_dict.numerical.bias: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([3, 128]).\n\tsize mismatch for encoder.encoders.constructor_standings.encoder.encoder_dict.numerical.mean: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for encoder.encoders.constructor_standings.encoder.encoder_dict.numerical.std: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([3]).\n\tsize mismatch for encoder.encoders.qualifying.encoder.encoder_dict.numerical.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([1, 128]).\n\tsize mismatch for encoder.encoders.qualifying.encoder.encoder_dict.numerical.bias: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([1, 128]).\n\tsize mismatch for encoder.encoders.qualifying.encoder.encoder_dict.numerical.mean: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1]).\n\tsize mismatch for encoder.encoders.qualifying.encoder.encoder_dict.numerical.std: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([1])."
          ]
        }
      ],
      "source": [
        "# model.load_state_dict(torch.load('best_model_GAT_head2.pth', map_location=torch.device('cpu')))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
